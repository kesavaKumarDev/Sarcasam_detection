{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6556321,"sourceType":"datasetVersion","datasetId":3788507}],"dockerImageVersionId":30009,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sarcasm Detection using the Pre-Trained BERT model from Transformers ","metadata":{}},{"cell_type":"code","source":"pip install --upgrade transformers","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:54:50.435733Z","iopub.execute_input":"2024-03-21T04:54:50.436126Z","iopub.status.idle":"2024-03-21T04:55:20.394415Z","shell.execute_reply.started":"2024-03-21T04:54:50.436090Z","shell.execute_reply":"2024-03-21T04:55:20.393357Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting transformers\n  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n\u001b[K     |████████████████████████████████| 7.2 MB 5.8 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2020.4.4)\nRequirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.23.0)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n  Downloading tokenizers-0.13.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[K     |████████████████████████████████| 7.8 MB 57.8 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (20.1)\nRequirement already satisfied, skipping upgrade: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.45.0)\nRequirement already satisfied, skipping upgrade: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (5.3.1)\nRequirement already satisfied, skipping upgrade: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.18.5)\nCollecting safetensors>=0.3.1\n  Downloading safetensors-0.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[K     |████████████████████████████████| 1.3 MB 50.0 MB/s eta 0:00:01\n\u001b[?25hCollecting huggingface-hub<1.0,>=0.14.1\n  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n\u001b[K     |████████████████████████████████| 268 kB 51.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.10)\nRequirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from transformers) (1.7.0)\nRequirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.9)\nRequirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\nRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.6.20)\nRequirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.24.3)\nRequirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (2.4.7)\nRequirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (1.14.0)\nRequirement already satisfied, skipping upgrade: fsspec in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (0.8.0)\nCollecting typing-extensions>=3.7.4.3\n  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\nRequirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.1.0)\nInstalling collected packages: tokenizers, safetensors, typing-extensions, huggingface-hub, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.7.0\n    Uninstalling tokenizers-0.7.0:\n      Successfully uninstalled tokenizers-0.7.0\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 3.7.4.1\n    Uninstalling typing-extensions-3.7.4.1:\n      Successfully uninstalled typing-extensions-3.7.4.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 2.11.0\n    Uninstalling transformers-2.11.0:\n      Successfully uninstalled transformers-2.11.0\n\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n\nbokeh 2.2.1 requires tornado>=5.1, but you'll have tornado 5.0.2 which is incompatible.\nallennlp 1.0.0 requires transformers<2.12,>=2.9, but you'll have transformers 4.30.2 which is incompatible.\naiobotocore 1.1.1 requires botocore<1.17.45,>=1.17.44, but you'll have botocore 1.17.56 which is incompatible.\nhuggingface-hub 0.16.4 requires packaging>=20.9, but you'll have packaging 20.1 which is incompatible.\u001b[0m\nSuccessfully installed huggingface-hub-0.16.4 safetensors-0.4.2 tokenizers-0.13.3 transformers-4.30.2 typing-extensions-4.7.1\n\u001b[33mWARNING: You are using pip version 20.2.2; however, version 24.0 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install torch --upgrade","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:55:20.396640Z","iopub.execute_input":"2024-03-21T04:55:20.396945Z","iopub.status.idle":"2024-03-21T04:57:11.357636Z","shell.execute_reply.started":"2024-03-21T04:55:20.396913Z","shell.execute_reply":"2024-03-21T04:57:11.356579Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torch\n  Downloading torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n\u001b[K     |████████████████████████████████| 887.5 MB 6.1 kB/s  eta 0:00:014    |████████▉                       | 244.9 MB 73.8 MB/s eta 0:00:09\n\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.7.1)\nCollecting nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[K     |████████████████████████████████| 317.1 MB 24 kB/s s eta 0:00:01\n\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\"\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[K     |████████████████████████████████| 557.1 MB 8.5 kB/s  eta 0:00:01\n\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\"\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[K     |████████████████████████████████| 849 kB 53.8 MB/s eta 0:00:01\n\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\"\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[K     |████████████████████████████████| 21.0 MB 49.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"->torch) (0.34.2)\nRequirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"->torch) (46.1.3.post20200325)\nInstalling collected packages: nvidia-cublas-cu11, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, torch\n  Attempting uninstall: torch\n    Found existing installation: torch 1.5.1\n    Uninstalling torch-1.5.1:\n      Successfully uninstalled torch-1.5.1\n\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n\nkornia 0.3.2 requires torch<1.6.0,>=1.5.0, but you'll have torch 1.13.1 which is incompatible.\nallennlp 1.0.0 requires torch<1.6.0,>=1.5.0, but you'll have torch 1.13.1 which is incompatible.\nallennlp 1.0.0 requires transformers<2.12,>=2.9, but you'll have transformers 4.30.2 which is incompatible.\u001b[0m\nSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n\u001b[33mWARNING: You are using pip version 20.2.2; however, version 24.0 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-21T04:57:11.359200Z","iopub.execute_input":"2024-03-21T04:57:11.359507Z","iopub.status.idle":"2024-03-21T04:57:11.370301Z","shell.execute_reply.started":"2024-03-21T04:57:11.359468Z","shell.execute_reply":"2024-03-21T04:57:11.369365Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/sarcasm-corpus-v2oraby-et-al/RQ-sarc-notsarc.csv\n/kaggle/input/sarcasm-corpus-v2oraby-et-al/GEN-sarc-notsarc.csv\n/kaggle/input/sarcasm-corpus-v2oraby-et-al/HYP-sarc-notsarc.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom transformers import TFBertModel, BertTokenizer\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:11.372135Z","iopub.execute_input":"2024-03-21T04:57:11.372598Z","iopub.status.idle":"2024-03-21T04:57:21.846432Z","shell.execute_reply.started":"2024-03-21T04:57:11.372568Z","shell.execute_reply":"2024-03-21T04:57:21.845498Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"gen = pd.read_csv(\"/kaggle/input/sarcasm-corpus-v2oraby-et-al/GEN-sarc-notsarc.csv\",index_col = \"id\")","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2024-03-21T04:57:21.850572Z","iopub.execute_input":"2024-03-21T04:57:21.850873Z","iopub.status.idle":"2024-03-21T04:57:21.916314Z","shell.execute_reply.started":"2024-03-21T04:57:21.850843Z","shell.execute_reply":"2024-03-21T04:57:21.915462Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"rq= pd.read_csv(\"/kaggle/input/sarcasm-corpus-v2oraby-et-al/HYP-sarc-notsarc.csv\",index_col = \"id\")","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:21.919682Z","iopub.execute_input":"2024-03-21T04:57:21.920024Z","iopub.status.idle":"2024-03-21T04:57:21.937281Z","shell.execute_reply.started":"2024-03-21T04:57:21.919992Z","shell.execute_reply":"2024-03-21T04:57:21.936577Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"hyp = pd.read_csv(\"/kaggle/input/sarcasm-corpus-v2oraby-et-al/RQ-sarc-notsarc.csv\",index_col = \"id\")","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:21.938669Z","iopub.execute_input":"2024-03-21T04:57:21.939073Z","iopub.status.idle":"2024-03-21T04:57:21.972062Z","shell.execute_reply.started":"2024-03-21T04:57:21.939031Z","shell.execute_reply":"2024-03-21T04:57:21.971127Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([gen,rq,hyp])","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:21.973413Z","iopub.execute_input":"2024-03-21T04:57:21.973717Z","iopub.status.idle":"2024-03-21T04:57:21.979323Z","shell.execute_reply.started":"2024-03-21T04:57:21.973687Z","shell.execute_reply":"2024-03-21T04:57:21.978344Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:21.980787Z","iopub.execute_input":"2024-03-21T04:57:21.981175Z","iopub.status.idle":"2024-03-21T04:57:21.994450Z","shell.execute_reply.started":"2024-03-21T04:57:21.981121Z","shell.execute_reply":"2024-03-21T04:57:21.993650Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(9386, 2)"},"metadata":{}}]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:21.995928Z","iopub.execute_input":"2024-03-21T04:57:21.996322Z","iopub.status.idle":"2024-03-21T04:57:22.015468Z","shell.execute_reply.started":"2024-03-21T04:57:21.996284Z","shell.execute_reply":"2024-03-21T04:57:22.014634Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"        class                                               text\nid                                                              \n1     notsarc  If that's true, then Freedom of Speech is doom...\n2     notsarc  Neener neener - is it time to go in from the p...\n3     notsarc  Just like the plastic gun fear, the armour pie...\n4     notsarc  So geology is a religion because we weren't he...\n5     notsarc  Well done Monty. Mark that up as your first ev...\n...       ...                                                ...\n1698     sarc  Tell me genius, how is me accurately and corre...\n1699     sarc  So you think it is a good idea for public scho...\n1700     sarc  Now settle down charlie, and try to think rati...\n1701     sarc  The VPC has a political agenda. The FBI? That ...\n1702     sarc  And I didn't. Did you note how I explicitly pu...\n\n[9386 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>notsarc</td>\n      <td>If that's true, then Freedom of Speech is doom...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>notsarc</td>\n      <td>Neener neener - is it time to go in from the p...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>notsarc</td>\n      <td>Just like the plastic gun fear, the armour pie...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>notsarc</td>\n      <td>So geology is a religion because we weren't he...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>notsarc</td>\n      <td>Well done Monty. Mark that up as your first ev...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1698</th>\n      <td>sarc</td>\n      <td>Tell me genius, how is me accurately and corre...</td>\n    </tr>\n    <tr>\n      <th>1699</th>\n      <td>sarc</td>\n      <td>So you think it is a good idea for public scho...</td>\n    </tr>\n    <tr>\n      <th>1700</th>\n      <td>sarc</td>\n      <td>Now settle down charlie, and try to think rati...</td>\n    </tr>\n    <tr>\n      <th>1701</th>\n      <td>sarc</td>\n      <td>The VPC has a political agenda. The FBI? That ...</td>\n    </tr>\n    <tr>\n      <th>1702</th>\n      <td>sarc</td>\n      <td>And I didn't. Did you note how I explicitly pu...</td>\n    </tr>\n  </tbody>\n</table>\n<p>9386 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\ndef lowercase_strings(x):\n    if isinstance(x, str):\n        return x.lower()\n    else:\n        return x\n\n# Applying the function to the entire DataFrame\ndf = data.applymap(lowercase_strings)\n\n# Displaying the resulting DataFrame\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:22.016685Z","iopub.execute_input":"2024-03-21T04:57:22.016981Z","iopub.status.idle":"2024-03-21T04:57:22.044536Z","shell.execute_reply.started":"2024-03-21T04:57:22.016945Z","shell.execute_reply":"2024-03-21T04:57:22.043527Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"        class                                               text\nid                                                              \n1     notsarc  if that's true, then freedom of speech is doom...\n2     notsarc  neener neener - is it time to go in from the p...\n3     notsarc  just like the plastic gun fear, the armour pie...\n4     notsarc  so geology is a religion because we weren't he...\n5     notsarc  well done monty. mark that up as your first ev...\n...       ...                                                ...\n1698     sarc  tell me genius, how is me accurately and corre...\n1699     sarc  so you think it is a good idea for public scho...\n1700     sarc  now settle down charlie, and try to think rati...\n1701     sarc  the vpc has a political agenda. the fbi? that ...\n1702     sarc  and i didn't. did you note how i explicitly pu...\n\n[9386 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Removing remove non-word and non-whitespace characters\ndf = df.replace(to_replace=r'[^\\w\\s]', value='', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:22.045706Z","iopub.execute_input":"2024-03-21T04:57:22.045970Z","iopub.status.idle":"2024-03-21T04:57:22.220234Z","shell.execute_reply.started":"2024-03-21T04:57:22.045944Z","shell.execute_reply":"2024-03-21T04:57:22.219239Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:22.221402Z","iopub.execute_input":"2024-03-21T04:57:22.221706Z","iopub.status.idle":"2024-03-21T04:57:22.235414Z","shell.execute_reply.started":"2024-03-21T04:57:22.221676Z","shell.execute_reply":"2024-03-21T04:57:22.234461Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"        class                                               text\nid                                                              \n1     notsarc  if thats true then freedom of speech is doomed...\n2     notsarc  neener neener  is it time to go in from the pl...\n3     notsarc  just like the plastic gun fear the armour pier...\n4     notsarc  so geology is a religion because we werent her...\n5     notsarc  well done monty mark that up as your first eve...\n...       ...                                                ...\n1698     sarc  tell me genius how is me accurately and correc...\n1699     sarc  so you think it is a good idea for public scho...\n1700     sarc  now settle down charlie and try to think ratio...\n1701     sarc  the vpc has a political agenda the fbi that is...\n1702     sarc  and i didnt did you note how i explicitly put ...\n\n[9386 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>notsarc</td>\n      <td>if thats true then freedom of speech is doomed...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>notsarc</td>\n      <td>neener neener  is it time to go in from the pl...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>notsarc</td>\n      <td>just like the plastic gun fear the armour pier...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>notsarc</td>\n      <td>so geology is a religion because we werent her...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>notsarc</td>\n      <td>well done monty mark that up as your first eve...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1698</th>\n      <td>sarc</td>\n      <td>tell me genius how is me accurately and correc...</td>\n    </tr>\n    <tr>\n      <th>1699</th>\n      <td>sarc</td>\n      <td>so you think it is a good idea for public scho...</td>\n    </tr>\n    <tr>\n      <th>1700</th>\n      <td>sarc</td>\n      <td>now settle down charlie and try to think ratio...</td>\n    </tr>\n    <tr>\n      <th>1701</th>\n      <td>sarc</td>\n      <td>the vpc has a political agenda the fbi that is...</td>\n    </tr>\n    <tr>\n      <th>1702</th>\n      <td>sarc</td>\n      <td>and i didnt did you note how i explicitly put ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>9386 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Removing digits\ndf = df.replace(to_replace=r'\\d', value='', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:22.237034Z","iopub.execute_input":"2024-03-21T04:57:22.237469Z","iopub.status.idle":"2024-03-21T04:57:22.338942Z","shell.execute_reply.started":"2024-03-21T04:57:22.237427Z","shell.execute_reply":"2024-03-21T04:57:22.338214Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:22.340270Z","iopub.execute_input":"2024-03-21T04:57:22.340640Z","iopub.status.idle":"2024-03-21T04:57:22.347445Z","shell.execute_reply.started":"2024-03-21T04:57:22.340607Z","shell.execute_reply":"2024-03-21T04:57:22.346593Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"class    object\ntext     object\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df['text'] = df['text'].apply(lambda x: str(x))","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:22.348988Z","iopub.execute_input":"2024-03-21T04:57:22.349286Z","iopub.status.idle":"2024-03-21T04:57:22.362486Z","shell.execute_reply.started":"2024-03-21T04:57:22.349257Z","shell.execute_reply":"2024-03-21T04:57:22.361522Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\n\ndf['text'] = df['text'].apply(word_tokenize)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:22.363877Z","iopub.execute_input":"2024-03-21T04:57:22.364236Z","iopub.status.idle":"2024-03-21T04:57:27.375782Z","shell.execute_reply.started":"2024-03-21T04:57:22.364199Z","shell.execute_reply":"2024-03-21T04:57:27.375005Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:27.377059Z","iopub.execute_input":"2024-03-21T04:57:27.377372Z","iopub.status.idle":"2024-03-21T04:57:27.404919Z","shell.execute_reply.started":"2024-03-21T04:57:27.377345Z","shell.execute_reply":"2024-03-21T04:57:27.404016Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"        class                                               text\nid                                                              \n1     notsarc  [if, thats, true, then, freedom, of, speech, i...\n2     notsarc  [neener, neener, is, it, time, to, go, in, fro...\n3     notsarc  [just, like, the, plastic, gun, fear, the, arm...\n4     notsarc  [so, geology, is, a, religion, because, we, we...\n5     notsarc  [well, done, monty, mark, that, up, as, your, ...\n...       ...                                                ...\n1698     sarc  [tell, me, genius, how, is, me, accurately, an...\n1699     sarc  [so, you, think, it, is, a, good, idea, for, p...\n1700     sarc  [now, settle, down, charlie, and, try, to, thi...\n1701     sarc  [the, vpc, has, a, political, agenda, the, fbi...\n1702     sarc  [and, i, didnt, did, you, note, how, i, explic...\n\n[9386 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>notsarc</td>\n      <td>[if, thats, true, then, freedom, of, speech, i...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>notsarc</td>\n      <td>[neener, neener, is, it, time, to, go, in, fro...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>notsarc</td>\n      <td>[just, like, the, plastic, gun, fear, the, arm...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>notsarc</td>\n      <td>[so, geology, is, a, religion, because, we, we...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>notsarc</td>\n      <td>[well, done, monty, mark, that, up, as, your, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1698</th>\n      <td>sarc</td>\n      <td>[tell, me, genius, how, is, me, accurately, an...</td>\n    </tr>\n    <tr>\n      <th>1699</th>\n      <td>sarc</td>\n      <td>[so, you, think, it, is, a, good, idea, for, p...</td>\n    </tr>\n    <tr>\n      <th>1700</th>\n      <td>sarc</td>\n      <td>[now, settle, down, charlie, and, try, to, thi...</td>\n    </tr>\n    <tr>\n      <th>1701</th>\n      <td>sarc</td>\n      <td>[the, vpc, has, a, political, agenda, the, fbi...</td>\n    </tr>\n    <tr>\n      <th>1702</th>\n      <td>sarc</td>\n      <td>[and, i, didnt, did, you, note, how, i, explic...</td>\n    </tr>\n  </tbody>\n</table>\n<p>9386 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import nltk\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nimport pandas as pd\n\n# Initialize the Porter Stemmer\nstemmer = PorterStemmer()\n\n# Define a function to perform stemming on the 'text' column\ndef stem_words(words):\n    return [stemmer.stem(word) for word in words]\n\n# Define a function to perform stemming on the 'text' column\ndef stem_words(words):\n    return [stemmer.stem(word) for word in words]\n\n# Apply the function to the 'text' column and create a new column 'stemmed_text'\ndf['stemmed_messages'] = df['text'].apply(stem_words)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:27.406557Z","iopub.execute_input":"2024-03-21T04:57:27.406973Z","iopub.status.idle":"2024-03-21T04:57:40.937468Z","shell.execute_reply.started":"2024-03-21T04:57:27.406934Z","shell.execute_reply":"2024-03-21T04:57:40.936548Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:40.938813Z","iopub.execute_input":"2024-03-21T04:57:40.939131Z","iopub.status.idle":"2024-03-21T04:57:40.972443Z","shell.execute_reply.started":"2024-03-21T04:57:40.939101Z","shell.execute_reply":"2024-03-21T04:57:40.971482Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"        class                                               text  \\\nid                                                                 \n1     notsarc  [if, thats, true, then, freedom, of, speech, i...   \n2     notsarc  [neener, neener, is, it, time, to, go, in, fro...   \n3     notsarc  [just, like, the, plastic, gun, fear, the, arm...   \n4     notsarc  [so, geology, is, a, religion, because, we, we...   \n5     notsarc  [well, done, monty, mark, that, up, as, your, ...   \n...       ...                                                ...   \n1698     sarc  [tell, me, genius, how, is, me, accurately, an...   \n1699     sarc  [so, you, think, it, is, a, good, idea, for, p...   \n1700     sarc  [now, settle, down, charlie, and, try, to, thi...   \n1701     sarc  [the, vpc, has, a, political, agenda, the, fbi...   \n1702     sarc  [and, i, didnt, did, you, note, how, i, explic...   \n\n                                       stemmed_messages  \nid                                                       \n1     [if, that, true, then, freedom, of, speech, is...  \n2     [neener, neener, is, it, time, to, go, in, fro...  \n3     [just, like, the, plastic, gun, fear, the, arm...  \n4     [so, geolog, is, a, religion, becaus, we, were...  \n5     [well, done, monti, mark, that, up, as, your, ...  \n...                                                 ...  \n1698  [tell, me, geniu, how, is, me, accur, and, cor...  \n1699  [so, you, think, it, is, a, good, idea, for, p...  \n1700  [now, settl, down, charli, and, tri, to, think...  \n1701  [the, vpc, ha, a, polit, agenda, the, fbi, tha...  \n1702  [and, i, didnt, did, you, note, how, i, explic...  \n\n[9386 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n      <th>stemmed_messages</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>notsarc</td>\n      <td>[if, thats, true, then, freedom, of, speech, i...</td>\n      <td>[if, that, true, then, freedom, of, speech, is...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>notsarc</td>\n      <td>[neener, neener, is, it, time, to, go, in, fro...</td>\n      <td>[neener, neener, is, it, time, to, go, in, fro...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>notsarc</td>\n      <td>[just, like, the, plastic, gun, fear, the, arm...</td>\n      <td>[just, like, the, plastic, gun, fear, the, arm...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>notsarc</td>\n      <td>[so, geology, is, a, religion, because, we, we...</td>\n      <td>[so, geolog, is, a, religion, becaus, we, were...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>notsarc</td>\n      <td>[well, done, monty, mark, that, up, as, your, ...</td>\n      <td>[well, done, monti, mark, that, up, as, your, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1698</th>\n      <td>sarc</td>\n      <td>[tell, me, genius, how, is, me, accurately, an...</td>\n      <td>[tell, me, geniu, how, is, me, accur, and, cor...</td>\n    </tr>\n    <tr>\n      <th>1699</th>\n      <td>sarc</td>\n      <td>[so, you, think, it, is, a, good, idea, for, p...</td>\n      <td>[so, you, think, it, is, a, good, idea, for, p...</td>\n    </tr>\n    <tr>\n      <th>1700</th>\n      <td>sarc</td>\n      <td>[now, settle, down, charlie, and, try, to, thi...</td>\n      <td>[now, settl, down, charli, and, tri, to, think...</td>\n    </tr>\n    <tr>\n      <th>1701</th>\n      <td>sarc</td>\n      <td>[the, vpc, has, a, political, agenda, the, fbi...</td>\n      <td>[the, vpc, ha, a, polit, agenda, the, fbi, tha...</td>\n    </tr>\n    <tr>\n      <th>1702</th>\n      <td>sarc</td>\n      <td>[and, i, didnt, did, you, note, how, i, explic...</td>\n      <td>[and, i, didnt, did, you, note, how, i, explic...</td>\n    </tr>\n  </tbody>\n</table>\n<p>9386 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import nltk\nnltk.download('averaged_perceptron_tagger')\nimport nltk\nnltk.download('wordnet')\n\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nimport pandas as pd\n\n# initialize lemmatizer\nlemmatizer = WordNetLemmatizer()\n\n# define function to lemmatize tokens\ndef lemmatize_tokens(tokens):\n    # convert POS tag to WordNet format\n    def get_wordnet_pos(word):\n        tag = nltk.pos_tag([word])[0][1][0].upper()\n        tag_dict = {\"J\": wordnet.ADJ,\n                    \"N\": wordnet.NOUN,\n                    \"V\": wordnet.VERB,\n                    \"R\": wordnet.ADV}\n        return tag_dict.get(tag, wordnet.NOUN)\n    \n    # lemmatize tokens\n    lemmas = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]\n    \n    # return lemmatized tokens as a list\n    return lemmas\n\n# apply lemmatization function to column of dataframe\ndf['lemmatized_messages'] = df['text'].apply(lemmatize_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:57:40.974096Z","iopub.execute_input":"2024-03-21T04:57:40.974547Z","iopub.status.idle":"2024-03-21T04:58:59.485724Z","shell.execute_reply.started":"2024-03-21T04:57:40.974504Z","shell.execute_reply":"2024-03-21T04:58:59.484853Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:58:59.486969Z","iopub.execute_input":"2024-03-21T04:58:59.487286Z","iopub.status.idle":"2024-03-21T04:58:59.529880Z","shell.execute_reply.started":"2024-03-21T04:58:59.487256Z","shell.execute_reply":"2024-03-21T04:58:59.529088Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"        class                                               text  \\\nid                                                                 \n1     notsarc  [if, thats, true, then, freedom, of, speech, i...   \n2     notsarc  [neener, neener, is, it, time, to, go, in, fro...   \n3     notsarc  [just, like, the, plastic, gun, fear, the, arm...   \n4     notsarc  [so, geology, is, a, religion, because, we, we...   \n5     notsarc  [well, done, monty, mark, that, up, as, your, ...   \n...       ...                                                ...   \n1698     sarc  [tell, me, genius, how, is, me, accurately, an...   \n1699     sarc  [so, you, think, it, is, a, good, idea, for, p...   \n1700     sarc  [now, settle, down, charlie, and, try, to, thi...   \n1701     sarc  [the, vpc, has, a, political, agenda, the, fbi...   \n1702     sarc  [and, i, didnt, did, you, note, how, i, explic...   \n\n                                       stemmed_messages  \\\nid                                                        \n1     [if, that, true, then, freedom, of, speech, is...   \n2     [neener, neener, is, it, time, to, go, in, fro...   \n3     [just, like, the, plastic, gun, fear, the, arm...   \n4     [so, geolog, is, a, religion, becaus, we, were...   \n5     [well, done, monti, mark, that, up, as, your, ...   \n...                                                 ...   \n1698  [tell, me, geniu, how, is, me, accur, and, cor...   \n1699  [so, you, think, it, is, a, good, idea, for, p...   \n1700  [now, settl, down, charli, and, tri, to, think...   \n1701  [the, vpc, ha, a, polit, agenda, the, fbi, tha...   \n1702  [and, i, didnt, did, you, note, how, i, explic...   \n\n                                    lemmatized_messages  \nid                                                       \n1     [if, thats, true, then, freedom, of, speech, b...  \n2     [neener, neener, be, it, time, to, go, in, fro...  \n3     [just, like, the, plastic, gun, fear, the, arm...  \n4     [so, geology, be, a, religion, because, we, we...  \n5     [well, do, monty, mark, that, up, a, your, fir...  \n...                                                 ...  \n1698  [tell, me, genius, how, be, me, accurately, an...  \n1699  [so, you, think, it, be, a, good, idea, for, p...  \n1700  [now, settle, down, charlie, and, try, to, thi...  \n1701  [the, vpc, have, a, political, agenda, the, fb...  \n1702  [and, i, didnt, do, you, note, how, i, explici...  \n\n[9386 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n      <th>stemmed_messages</th>\n      <th>lemmatized_messages</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>notsarc</td>\n      <td>[if, thats, true, then, freedom, of, speech, i...</td>\n      <td>[if, that, true, then, freedom, of, speech, is...</td>\n      <td>[if, thats, true, then, freedom, of, speech, b...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>notsarc</td>\n      <td>[neener, neener, is, it, time, to, go, in, fro...</td>\n      <td>[neener, neener, is, it, time, to, go, in, fro...</td>\n      <td>[neener, neener, be, it, time, to, go, in, fro...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>notsarc</td>\n      <td>[just, like, the, plastic, gun, fear, the, arm...</td>\n      <td>[just, like, the, plastic, gun, fear, the, arm...</td>\n      <td>[just, like, the, plastic, gun, fear, the, arm...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>notsarc</td>\n      <td>[so, geology, is, a, religion, because, we, we...</td>\n      <td>[so, geolog, is, a, religion, becaus, we, were...</td>\n      <td>[so, geology, be, a, religion, because, we, we...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>notsarc</td>\n      <td>[well, done, monty, mark, that, up, as, your, ...</td>\n      <td>[well, done, monti, mark, that, up, as, your, ...</td>\n      <td>[well, do, monty, mark, that, up, a, your, fir...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1698</th>\n      <td>sarc</td>\n      <td>[tell, me, genius, how, is, me, accurately, an...</td>\n      <td>[tell, me, geniu, how, is, me, accur, and, cor...</td>\n      <td>[tell, me, genius, how, be, me, accurately, an...</td>\n    </tr>\n    <tr>\n      <th>1699</th>\n      <td>sarc</td>\n      <td>[so, you, think, it, is, a, good, idea, for, p...</td>\n      <td>[so, you, think, it, is, a, good, idea, for, p...</td>\n      <td>[so, you, think, it, be, a, good, idea, for, p...</td>\n    </tr>\n    <tr>\n      <th>1700</th>\n      <td>sarc</td>\n      <td>[now, settle, down, charlie, and, try, to, thi...</td>\n      <td>[now, settl, down, charli, and, tri, to, think...</td>\n      <td>[now, settle, down, charlie, and, try, to, thi...</td>\n    </tr>\n    <tr>\n      <th>1701</th>\n      <td>sarc</td>\n      <td>[the, vpc, has, a, political, agenda, the, fbi...</td>\n      <td>[the, vpc, ha, a, polit, agenda, the, fbi, tha...</td>\n      <td>[the, vpc, have, a, political, agenda, the, fb...</td>\n    </tr>\n    <tr>\n      <th>1702</th>\n      <td>sarc</td>\n      <td>[and, i, didnt, did, you, note, how, i, explic...</td>\n      <td>[and, i, didnt, did, you, note, how, i, explic...</td>\n      <td>[and, i, didnt, do, you, note, how, i, explici...</td>\n    </tr>\n  </tbody>\n</table>\n<p>9386 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\ndf['class'] = label_encoder.fit_transform(df['class'])","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:58:59.530890Z","iopub.execute_input":"2024-03-21T04:58:59.531190Z","iopub.status.idle":"2024-03-21T04:58:59.540769Z","shell.execute_reply.started":"2024-03-21T04:58:59.531146Z","shell.execute_reply":"2024-03-21T04:58:59.539809Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:58:59.542842Z","iopub.execute_input":"2024-03-21T04:58:59.543277Z","iopub.status.idle":"2024-03-21T04:58:59.588417Z","shell.execute_reply.started":"2024-03-21T04:58:59.543234Z","shell.execute_reply":"2024-03-21T04:58:59.587287Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"      class                                               text  \\\nid                                                               \n1         0  [if, thats, true, then, freedom, of, speech, i...   \n2         0  [neener, neener, is, it, time, to, go, in, fro...   \n3         0  [just, like, the, plastic, gun, fear, the, arm...   \n4         0  [so, geology, is, a, religion, because, we, we...   \n5         0  [well, done, monty, mark, that, up, as, your, ...   \n...     ...                                                ...   \n1698      1  [tell, me, genius, how, is, me, accurately, an...   \n1699      1  [so, you, think, it, is, a, good, idea, for, p...   \n1700      1  [now, settle, down, charlie, and, try, to, thi...   \n1701      1  [the, vpc, has, a, political, agenda, the, fbi...   \n1702      1  [and, i, didnt, did, you, note, how, i, explic...   \n\n                                       stemmed_messages  \\\nid                                                        \n1     [if, that, true, then, freedom, of, speech, is...   \n2     [neener, neener, is, it, time, to, go, in, fro...   \n3     [just, like, the, plastic, gun, fear, the, arm...   \n4     [so, geolog, is, a, religion, becaus, we, were...   \n5     [well, done, monti, mark, that, up, as, your, ...   \n...                                                 ...   \n1698  [tell, me, geniu, how, is, me, accur, and, cor...   \n1699  [so, you, think, it, is, a, good, idea, for, p...   \n1700  [now, settl, down, charli, and, tri, to, think...   \n1701  [the, vpc, ha, a, polit, agenda, the, fbi, tha...   \n1702  [and, i, didnt, did, you, note, how, i, explic...   \n\n                                    lemmatized_messages  \nid                                                       \n1     [if, thats, true, then, freedom, of, speech, b...  \n2     [neener, neener, be, it, time, to, go, in, fro...  \n3     [just, like, the, plastic, gun, fear, the, arm...  \n4     [so, geology, be, a, religion, because, we, we...  \n5     [well, do, monty, mark, that, up, a, your, fir...  \n...                                                 ...  \n1698  [tell, me, genius, how, be, me, accurately, an...  \n1699  [so, you, think, it, be, a, good, idea, for, p...  \n1700  [now, settle, down, charlie, and, try, to, thi...  \n1701  [the, vpc, have, a, political, agenda, the, fb...  \n1702  [and, i, didnt, do, you, note, how, i, explici...  \n\n[9386 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n      <th>stemmed_messages</th>\n      <th>lemmatized_messages</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>[if, thats, true, then, freedom, of, speech, i...</td>\n      <td>[if, that, true, then, freedom, of, speech, is...</td>\n      <td>[if, thats, true, then, freedom, of, speech, b...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>[neener, neener, is, it, time, to, go, in, fro...</td>\n      <td>[neener, neener, is, it, time, to, go, in, fro...</td>\n      <td>[neener, neener, be, it, time, to, go, in, fro...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>[just, like, the, plastic, gun, fear, the, arm...</td>\n      <td>[just, like, the, plastic, gun, fear, the, arm...</td>\n      <td>[just, like, the, plastic, gun, fear, the, arm...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>[so, geology, is, a, religion, because, we, we...</td>\n      <td>[so, geolog, is, a, religion, becaus, we, were...</td>\n      <td>[so, geology, be, a, religion, because, we, we...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>[well, done, monty, mark, that, up, as, your, ...</td>\n      <td>[well, done, monti, mark, that, up, as, your, ...</td>\n      <td>[well, do, monty, mark, that, up, a, your, fir...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1698</th>\n      <td>1</td>\n      <td>[tell, me, genius, how, is, me, accurately, an...</td>\n      <td>[tell, me, geniu, how, is, me, accur, and, cor...</td>\n      <td>[tell, me, genius, how, be, me, accurately, an...</td>\n    </tr>\n    <tr>\n      <th>1699</th>\n      <td>1</td>\n      <td>[so, you, think, it, is, a, good, idea, for, p...</td>\n      <td>[so, you, think, it, is, a, good, idea, for, p...</td>\n      <td>[so, you, think, it, be, a, good, idea, for, p...</td>\n    </tr>\n    <tr>\n      <th>1700</th>\n      <td>1</td>\n      <td>[now, settle, down, charlie, and, try, to, thi...</td>\n      <td>[now, settl, down, charli, and, tri, to, think...</td>\n      <td>[now, settle, down, charlie, and, try, to, thi...</td>\n    </tr>\n    <tr>\n      <th>1701</th>\n      <td>1</td>\n      <td>[the, vpc, has, a, political, agenda, the, fbi...</td>\n      <td>[the, vpc, ha, a, polit, agenda, the, fbi, tha...</td>\n      <td>[the, vpc, have, a, political, agenda, the, fb...</td>\n    </tr>\n    <tr>\n      <th>1702</th>\n      <td>1</td>\n      <td>[and, i, didnt, did, you, note, how, i, explic...</td>\n      <td>[and, i, didnt, did, you, note, how, i, explic...</td>\n      <td>[and, i, didnt, do, you, note, how, i, explici...</td>\n    </tr>\n  </tbody>\n</table>\n<p>9386 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sentences=df['lemmatized_messages']\nlabels=df['class']","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:58:59.589999Z","iopub.execute_input":"2024-03-21T04:58:59.590420Z","iopub.status.idle":"2024-03-21T04:58:59.598019Z","shell.execute_reply.started":"2024-03-21T04:58:59.590386Z","shell.execute_reply":"2024-03-21T04:58:59.597029Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"**Bert**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom transformers import TFBertModel, BertTokenizer\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:58:59.599415Z","iopub.execute_input":"2024-03-21T04:58:59.599801Z","iopub.status.idle":"2024-03-21T04:58:59.610064Z","shell.execute_reply.started":"2024-03-21T04:58:59.599760Z","shell.execute_reply":"2024-03-21T04:58:59.609147Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\ntokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME,do_lower_case = True)\n\ndef encoder(sentences, max_length=16):\n    ids = []\n    for sentence in sentences:\n        encoding = tokenizer.encode_plus(\n            sentence,\n            max_length=max_length,\n            truncation=True,\n            add_special_tokens=True,\n            return_token_type_ids=False,\n            pad_to_max_length=True,\n            return_attention_mask=False\n        )\n        ids.append(encoding['input_ids'])\n    return ids","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:58:59.611535Z","iopub.execute_input":"2024-03-21T04:58:59.611855Z","iopub.status.idle":"2024-03-21T04:59:00.886168Z","shell.execute_reply.started":"2024-03-21T04:58:59.611819Z","shell.execute_reply":"2024-03-21T04:59:00.885254Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading vocab.txt', max=231508.0, style=ProgressStyle…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78f438fdd64642e6a77dfa5f80ce3499"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading tokenizer_config.json', max=48.0, style=Progr…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e796ccc97d745e8abcb77c640168bb9"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading config.json', max=570.0, style=ProgressStyle(…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbeea3a5a06e4fa8944316070f50f95a"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"encoded_ids = encoder(sentences)\n\n# Convert to TensorFlow tensors\ninput_ids = tf.convert_to_tensor(encoded_ids)\nlabels = tf.convert_to_tensor(labels)\n\nprint(\"Shape of input_ids:\", input_ids.shape)\nprint(\"Shape of labels:\", labels.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:59:00.887750Z","iopub.execute_input":"2024-03-21T04:59:00.888074Z","iopub.status.idle":"2024-03-21T04:59:04.189332Z","shell.execute_reply.started":"2024-03-21T04:59:00.888030Z","shell.execute_reply":"2024-03-21T04:59:04.188278Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2383: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"},{"name":"stdout","text":"Shape of input_ids: (9386, 16)\nShape of labels: (9386,)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Convert labels to a NumPy array\nlabels = np.array(labels)\n\n# Train test split\ntrain_sents, test_sents, train_labels, test_labels = train_test_split(sentences, labels, test_size=0.15)\n\n# Ensure train_sents and test_sents are lists of sentences\ntrain_sents = train_sents.tolist()\ntest_sents = test_sents.tolist()\n\n# Encode sentences\ntrain_ids = encoder(train_sents)\ntest_ids = encoder(test_sents)\n\n# Convert to TensorFlow tensors\ntrain_ids = tf.convert_to_tensor(train_ids)\ntest_ids = tf.convert_to_tensor(test_ids)\ntest_labels = tf.convert_to_tensor(test_labels)\ntrain_labels = tf.convert_to_tensor(train_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:59:04.190719Z","iopub.execute_input":"2024-03-21T04:59:04.191003Z","iopub.status.idle":"2024-03-21T04:59:05.732849Z","shell.execute_reply.started":"2024-03-21T04:59:04.190975Z","shell.execute_reply":"2024-03-21T04:59:05.732140Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"bert_encoder = TFBertModel.from_pretrained('bert-base-uncased')\ninput_word_ids = tf.keras.Input(shape=(16,), dtype=tf.int32, name=\"input_word_ids\")  \n# embedding = bert_encoder([input_word_ids])\n# dense = tf.keras.layers.Lambda(lambda seq: seq[:, 0, :])(embedding[0])\n# dense = tf.keras.layers.Dense(128, activation='relu')(dense)\n# dense = tf.keras.layers.Dropout(0.5)(dense)   \n# output = tf.keras.layers.Dense(1, activation='sigmoid')(dense)   \n\n\n# Get BERT embeddings\nembedding = bert_encoder(input_word_ids)[0]  # Extracting the sequence output from BERT\n\n# Add self-attention mechanism\nattention_probs = tf.keras.layers.Attention()([embedding, embedding])\n\n# Pool the output of BERT using mean pooling\npooled_output = tf.reduce_mean(attention_probs, axis=1)\n\n# Add dense layer and dropout\ndense = tf.keras.layers.Dense(128, activation='relu')(pooled_output)\ndense = tf.keras.layers.Dropout(0.5)(dense)\n\n# Output layer\noutput = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n\n# Define the model\nmodel = tf.keras.Model(inputs=input_word_ids, outputs=output)\n\n# model = tf.keras.Model(inputs=[input_word_ids], outputs=output) ","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:59:05.733996Z","iopub.execute_input":"2024-03-21T04:59:05.734290Z","iopub.status.idle":"2024-03-21T04:59:18.358602Z","shell.execute_reply.started":"2024-03-21T04:59:05.734264Z","shell.execute_reply":"2024-03-21T04:59:18.357864Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading model.safetensors', max=440449768.0, style=Pr…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c247d956ccd464daac7288dae3ccc22"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(tf.keras.optimizers.Adam(1e-7), loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:59:18.359667Z","iopub.execute_input":"2024-03-21T04:59:18.359962Z","iopub.status.idle":"2024-03-21T04:59:18.415725Z","shell.execute_reply.started":"2024-03-21T04:59:18.359921Z","shell.execute_reply":"2024-03-21T04:59:18.413885Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Model: \"functional_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_word_ids (InputLayer)     [(None, 16)]         0                                            \n__________________________________________________________________________________________________\ntf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_word_ids[0][0]             \n__________________________________________________________________________________________________\nattention (Attention)           (None, 16, 768)      0           tf_bert_model[0][0]              \n                                                                 tf_bert_model[0][0]              \n__________________________________________________________________________________________________\ntf_op_layer_Mean (TensorFlowOpL [(None, 768)]        0           attention[0][0]                  \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 128)          98432       tf_op_layer_Mean[0][0]           \n__________________________________________________________________________________________________\ndropout_37 (Dropout)            (None, 128)          0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 1)            129         dropout_37[0][0]                 \n==================================================================================================\nTotal params: 109,580,801\nTrainable params: 109,580,801\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True)\nhistory = model.fit(x=train_ids, y=train_labels, epochs=200, batch_size=32, validation_data=(test_ids, test_labels), callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2024-03-21T04:59:18.425861Z","iopub.execute_input":"2024-03-21T04:59:18.426213Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/200\n250/250 [==============================] - 26s 104ms/step - loss: 0.7249 - accuracy: 0.5010 - val_loss: 0.6945 - val_accuracy: 0.5270\nEpoch 2/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.7168 - accuracy: 0.5046 - val_loss: 0.6890 - val_accuracy: 0.5518\nEpoch 3/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.7090 - accuracy: 0.5226 - val_loss: 0.6838 - val_accuracy: 0.5696\nEpoch 4/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.7041 - accuracy: 0.5269 - val_loss: 0.6794 - val_accuracy: 0.5866\nEpoch 5/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6973 - accuracy: 0.5385 - val_loss: 0.6752 - val_accuracy: 0.5952\nEpoch 6/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6935 - accuracy: 0.5445 - val_loss: 0.6712 - val_accuracy: 0.6016\nEpoch 7/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.6890 - accuracy: 0.5501 - val_loss: 0.6673 - val_accuracy: 0.6072\nEpoch 8/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6876 - accuracy: 0.5511 - val_loss: 0.6639 - val_accuracy: 0.6115\nEpoch 9/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6789 - accuracy: 0.5748 - val_loss: 0.6605 - val_accuracy: 0.6101\nEpoch 10/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.6773 - accuracy: 0.5741 - val_loss: 0.6573 - val_accuracy: 0.6094\nEpoch 11/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6733 - accuracy: 0.5808 - val_loss: 0.6543 - val_accuracy: 0.6165\nEpoch 12/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6699 - accuracy: 0.5939 - val_loss: 0.6514 - val_accuracy: 0.6193\nEpoch 13/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6717 - accuracy: 0.5849 - val_loss: 0.6488 - val_accuracy: 0.6207\nEpoch 14/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6648 - accuracy: 0.5914 - val_loss: 0.6461 - val_accuracy: 0.6278\nEpoch 15/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6611 - accuracy: 0.6013 - val_loss: 0.6435 - val_accuracy: 0.6286\nEpoch 16/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6594 - accuracy: 0.6126 - val_loss: 0.6411 - val_accuracy: 0.6357\nEpoch 17/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.6586 - accuracy: 0.6114 - val_loss: 0.6389 - val_accuracy: 0.6399\nEpoch 18/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6526 - accuracy: 0.6179 - val_loss: 0.6368 - val_accuracy: 0.6463\nEpoch 19/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.6545 - accuracy: 0.6133 - val_loss: 0.6348 - val_accuracy: 0.6442\nEpoch 20/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6503 - accuracy: 0.6188 - val_loss: 0.6329 - val_accuracy: 0.6449\nEpoch 21/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6490 - accuracy: 0.6222 - val_loss: 0.6311 - val_accuracy: 0.6470\nEpoch 22/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6455 - accuracy: 0.6202 - val_loss: 0.6293 - val_accuracy: 0.6548\nEpoch 23/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6410 - accuracy: 0.6302 - val_loss: 0.6276 - val_accuracy: 0.6577\nEpoch 24/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6396 - accuracy: 0.6359 - val_loss: 0.6258 - val_accuracy: 0.6591\nEpoch 25/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6389 - accuracy: 0.6359 - val_loss: 0.6243 - val_accuracy: 0.6584\nEpoch 26/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6354 - accuracy: 0.6420 - val_loss: 0.6227 - val_accuracy: 0.6577\nEpoch 27/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.6373 - accuracy: 0.6337 - val_loss: 0.6215 - val_accuracy: 0.6584\nEpoch 28/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.6362 - accuracy: 0.6375 - val_loss: 0.6201 - val_accuracy: 0.6591\nEpoch 29/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6348 - accuracy: 0.6465 - val_loss: 0.6189 - val_accuracy: 0.6612\nEpoch 30/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.6324 - accuracy: 0.6394 - val_loss: 0.6179 - val_accuracy: 0.6619\nEpoch 31/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6303 - accuracy: 0.6473 - val_loss: 0.6169 - val_accuracy: 0.6634\nEpoch 32/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6256 - accuracy: 0.6510 - val_loss: 0.6160 - val_accuracy: 0.6655\nEpoch 33/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6262 - accuracy: 0.6538 - val_loss: 0.6148 - val_accuracy: 0.6690\nEpoch 34/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6280 - accuracy: 0.6529 - val_loss: 0.6140 - val_accuracy: 0.6683\nEpoch 35/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6262 - accuracy: 0.6533 - val_loss: 0.6130 - val_accuracy: 0.6726\nEpoch 36/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6217 - accuracy: 0.6554 - val_loss: 0.6121 - val_accuracy: 0.6676\nEpoch 37/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6215 - accuracy: 0.6556 - val_loss: 0.6112 - val_accuracy: 0.6712\nEpoch 38/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6212 - accuracy: 0.6640 - val_loss: 0.6104 - val_accuracy: 0.6712\nEpoch 39/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6175 - accuracy: 0.6616 - val_loss: 0.6095 - val_accuracy: 0.6697\nEpoch 40/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.6210 - accuracy: 0.6591 - val_loss: 0.6090 - val_accuracy: 0.6705\nEpoch 41/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6173 - accuracy: 0.6584 - val_loss: 0.6084 - val_accuracy: 0.6669\nEpoch 42/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6143 - accuracy: 0.6627 - val_loss: 0.6074 - val_accuracy: 0.6712\nEpoch 43/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.6121 - accuracy: 0.6655 - val_loss: 0.6066 - val_accuracy: 0.6712\nEpoch 44/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.6124 - accuracy: 0.6681 - val_loss: 0.6060 - val_accuracy: 0.6705\nEpoch 45/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6106 - accuracy: 0.6668 - val_loss: 0.6052 - val_accuracy: 0.6690\nEpoch 46/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6134 - accuracy: 0.6657 - val_loss: 0.6048 - val_accuracy: 0.6676\nEpoch 47/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6098 - accuracy: 0.6715 - val_loss: 0.6045 - val_accuracy: 0.6683\nEpoch 48/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.6080 - accuracy: 0.6696 - val_loss: 0.6040 - val_accuracy: 0.6697\nEpoch 49/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6076 - accuracy: 0.6716 - val_loss: 0.6034 - val_accuracy: 0.6705\nEpoch 50/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6071 - accuracy: 0.6721 - val_loss: 0.6028 - val_accuracy: 0.6705\nEpoch 51/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.6043 - accuracy: 0.6721 - val_loss: 0.6024 - val_accuracy: 0.6712\nEpoch 52/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6028 - accuracy: 0.6771 - val_loss: 0.6021 - val_accuracy: 0.6712\nEpoch 53/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.6067 - accuracy: 0.6754 - val_loss: 0.6019 - val_accuracy: 0.6697\nEpoch 54/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.6010 - accuracy: 0.6804 - val_loss: 0.6012 - val_accuracy: 0.6683\nEpoch 55/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.5991 - accuracy: 0.6790 - val_loss: 0.6009 - val_accuracy: 0.6683\nEpoch 56/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.5994 - accuracy: 0.6789 - val_loss: 0.6005 - val_accuracy: 0.6705\nEpoch 57/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.5969 - accuracy: 0.6795 - val_loss: 0.6003 - val_accuracy: 0.6733\nEpoch 58/200\n250/250 [==============================] - 24s 97ms/step - loss: 0.5958 - accuracy: 0.6841 - val_loss: 0.5996 - val_accuracy: 0.6726\nEpoch 59/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5944 - accuracy: 0.6833 - val_loss: 0.5989 - val_accuracy: 0.6733\nEpoch 60/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5932 - accuracy: 0.6881 - val_loss: 0.5991 - val_accuracy: 0.6726\nEpoch 61/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5937 - accuracy: 0.6844 - val_loss: 0.5991 - val_accuracy: 0.6754\nEpoch 62/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5938 - accuracy: 0.6868 - val_loss: 0.5984 - val_accuracy: 0.6705\nEpoch 63/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5915 - accuracy: 0.6868 - val_loss: 0.5977 - val_accuracy: 0.6733\nEpoch 64/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5905 - accuracy: 0.6878 - val_loss: 0.5976 - val_accuracy: 0.6733\nEpoch 65/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5903 - accuracy: 0.6878 - val_loss: 0.5976 - val_accuracy: 0.6719\nEpoch 66/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5870 - accuracy: 0.6934 - val_loss: 0.5970 - val_accuracy: 0.6726\nEpoch 67/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5875 - accuracy: 0.6850 - val_loss: 0.5962 - val_accuracy: 0.6733\nEpoch 68/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5878 - accuracy: 0.6929 - val_loss: 0.5964 - val_accuracy: 0.6740\nEpoch 69/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5805 - accuracy: 0.6998 - val_loss: 0.5962 - val_accuracy: 0.6733\nEpoch 70/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5850 - accuracy: 0.6910 - val_loss: 0.5957 - val_accuracy: 0.6733\nEpoch 71/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5849 - accuracy: 0.6927 - val_loss: 0.5955 - val_accuracy: 0.6733\nEpoch 72/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5815 - accuracy: 0.6933 - val_loss: 0.5952 - val_accuracy: 0.6733\nEpoch 73/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5784 - accuracy: 0.6977 - val_loss: 0.5946 - val_accuracy: 0.6726\nEpoch 74/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5798 - accuracy: 0.7012 - val_loss: 0.5945 - val_accuracy: 0.6747\nEpoch 75/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5781 - accuracy: 0.7014 - val_loss: 0.5953 - val_accuracy: 0.6761\nEpoch 76/200\n250/250 [==============================] - 24s 94ms/step - loss: 0.5776 - accuracy: 0.7026 - val_loss: 0.5947 - val_accuracy: 0.6747\nEpoch 77/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5791 - accuracy: 0.7041 - val_loss: 0.5936 - val_accuracy: 0.6811\nEpoch 78/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5755 - accuracy: 0.7037 - val_loss: 0.5940 - val_accuracy: 0.6783\nEpoch 79/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5731 - accuracy: 0.7056 - val_loss: 0.5939 - val_accuracy: 0.6804\nEpoch 80/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5709 - accuracy: 0.7082 - val_loss: 0.5940 - val_accuracy: 0.6818\nEpoch 81/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5712 - accuracy: 0.7064 - val_loss: 0.5934 - val_accuracy: 0.6839\nEpoch 82/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5724 - accuracy: 0.7003 - val_loss: 0.5927 - val_accuracy: 0.6832\nEpoch 83/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5684 - accuracy: 0.7068 - val_loss: 0.5928 - val_accuracy: 0.6861\nEpoch 84/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5723 - accuracy: 0.7041 - val_loss: 0.5934 - val_accuracy: 0.6847\nEpoch 85/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5690 - accuracy: 0.7106 - val_loss: 0.5931 - val_accuracy: 0.6839\nEpoch 86/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5695 - accuracy: 0.7091 - val_loss: 0.5928 - val_accuracy: 0.6854\nEpoch 87/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5709 - accuracy: 0.7067 - val_loss: 0.5925 - val_accuracy: 0.6861\nEpoch 88/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5680 - accuracy: 0.7061 - val_loss: 0.5920 - val_accuracy: 0.6875\nEpoch 89/200\n250/250 [==============================] - 24s 94ms/step - loss: 0.5668 - accuracy: 0.7112 - val_loss: 0.5921 - val_accuracy: 0.6847\nEpoch 90/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5655 - accuracy: 0.7137 - val_loss: 0.5926 - val_accuracy: 0.6861\nEpoch 91/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5593 - accuracy: 0.7161 - val_loss: 0.5923 - val_accuracy: 0.6847\nEpoch 92/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5634 - accuracy: 0.7098 - val_loss: 0.5928 - val_accuracy: 0.6847\nEpoch 93/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5615 - accuracy: 0.7125 - val_loss: 0.5926 - val_accuracy: 0.6847\nEpoch 94/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5611 - accuracy: 0.7126 - val_loss: 0.5930 - val_accuracy: 0.6861\nEpoch 95/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5556 - accuracy: 0.7182 - val_loss: 0.5918 - val_accuracy: 0.6854\nEpoch 96/200\n250/250 [==============================] - 24s 94ms/step - loss: 0.5542 - accuracy: 0.7187 - val_loss: 0.5922 - val_accuracy: 0.6854\nEpoch 97/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5559 - accuracy: 0.7229 - val_loss: 0.5925 - val_accuracy: 0.6854\nEpoch 98/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5544 - accuracy: 0.7221 - val_loss: 0.5925 - val_accuracy: 0.6875\nEpoch 99/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5503 - accuracy: 0.7242 - val_loss: 0.5933 - val_accuracy: 0.6896\nEpoch 100/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5561 - accuracy: 0.7216 - val_loss: 0.5926 - val_accuracy: 0.6896\nEpoch 101/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5525 - accuracy: 0.7186 - val_loss: 0.5915 - val_accuracy: 0.6847\nEpoch 102/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5559 - accuracy: 0.7251 - val_loss: 0.5920 - val_accuracy: 0.6889\nEpoch 103/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5447 - accuracy: 0.7296 - val_loss: 0.5924 - val_accuracy: 0.6903\nEpoch 104/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5505 - accuracy: 0.7259 - val_loss: 0.5927 - val_accuracy: 0.6932\nEpoch 105/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5469 - accuracy: 0.7234 - val_loss: 0.5922 - val_accuracy: 0.6896\nEpoch 106/200\n250/250 [==============================] - 24s 94ms/step - loss: 0.5488 - accuracy: 0.7221 - val_loss: 0.5917 - val_accuracy: 0.6925\nEpoch 107/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5460 - accuracy: 0.7276 - val_loss: 0.5920 - val_accuracy: 0.6925\nEpoch 108/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5410 - accuracy: 0.7315 - val_loss: 0.5926 - val_accuracy: 0.6932\nEpoch 109/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5453 - accuracy: 0.7304 - val_loss: 0.5923 - val_accuracy: 0.6946\nEpoch 110/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5369 - accuracy: 0.7388 - val_loss: 0.5921 - val_accuracy: 0.6932\nEpoch 111/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5418 - accuracy: 0.7271 - val_loss: 0.5921 - val_accuracy: 0.6925\nEpoch 112/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5434 - accuracy: 0.7311 - val_loss: 0.5916 - val_accuracy: 0.6939\nEpoch 113/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5389 - accuracy: 0.7353 - val_loss: 0.5917 - val_accuracy: 0.6939\nEpoch 114/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5349 - accuracy: 0.7324 - val_loss: 0.5937 - val_accuracy: 0.6953\nEpoch 115/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5366 - accuracy: 0.7367 - val_loss: 0.5924 - val_accuracy: 0.6932\nEpoch 116/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5377 - accuracy: 0.7369 - val_loss: 0.5935 - val_accuracy: 0.6953\nEpoch 117/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5317 - accuracy: 0.7355 - val_loss: 0.5927 - val_accuracy: 0.6925\nEpoch 118/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5327 - accuracy: 0.7390 - val_loss: 0.5933 - val_accuracy: 0.6960\nEpoch 119/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5355 - accuracy: 0.7359 - val_loss: 0.5937 - val_accuracy: 0.6974\nEpoch 120/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5350 - accuracy: 0.7353 - val_loss: 0.5932 - val_accuracy: 0.6953\nEpoch 121/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5282 - accuracy: 0.7407 - val_loss: 0.5935 - val_accuracy: 0.6967\nEpoch 122/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5281 - accuracy: 0.7413 - val_loss: 0.5950 - val_accuracy: 0.6967\nEpoch 123/200\n250/250 [==============================] - 24s 94ms/step - loss: 0.5238 - accuracy: 0.7447 - val_loss: 0.5942 - val_accuracy: 0.6960\nEpoch 124/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5234 - accuracy: 0.7437 - val_loss: 0.5952 - val_accuracy: 0.6960\nEpoch 125/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5275 - accuracy: 0.7439 - val_loss: 0.5950 - val_accuracy: 0.6967\nEpoch 126/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5254 - accuracy: 0.7428 - val_loss: 0.5956 - val_accuracy: 0.6946\nEpoch 127/200\n250/250 [==============================] - 24s 94ms/step - loss: 0.5259 - accuracy: 0.7423 - val_loss: 0.5949 - val_accuracy: 0.6960\nEpoch 128/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5244 - accuracy: 0.7410 - val_loss: 0.5964 - val_accuracy: 0.6918\nEpoch 129/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5227 - accuracy: 0.7467 - val_loss: 0.5973 - val_accuracy: 0.6911\nEpoch 130/200\n250/250 [==============================] - 24s 94ms/step - loss: 0.5246 - accuracy: 0.7435 - val_loss: 0.5963 - val_accuracy: 0.6932\nEpoch 131/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5172 - accuracy: 0.7482 - val_loss: 0.5968 - val_accuracy: 0.6953\nEpoch 132/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5239 - accuracy: 0.7434 - val_loss: 0.5956 - val_accuracy: 0.6960\nEpoch 133/200\n250/250 [==============================] - 24s 96ms/step - loss: 0.5198 - accuracy: 0.7466 - val_loss: 0.5964 - val_accuracy: 0.6960\nEpoch 134/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5177 - accuracy: 0.7493 - val_loss: 0.5966 - val_accuracy: 0.6946\nEpoch 135/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5138 - accuracy: 0.7486 - val_loss: 0.5971 - val_accuracy: 0.6939\nEpoch 136/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5110 - accuracy: 0.7491 - val_loss: 0.5972 - val_accuracy: 0.6960\nEpoch 137/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5124 - accuracy: 0.7546 - val_loss: 0.5977 - val_accuracy: 0.6953\nEpoch 138/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5109 - accuracy: 0.7563 - val_loss: 0.5977 - val_accuracy: 0.6989\nEpoch 139/200\n250/250 [==============================] - 24s 95ms/step - loss: 0.5129 - accuracy: 0.7524 - val_loss: 0.5996 - val_accuracy: 0.6925\nEpoch 140/200\n171/250 [===================>..........] - ETA: 7s - loss: 0.5060 - accuracy: 0.7551","output_type":"stream"}]},{"cell_type":"code","source":"def plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n\nplot_graphs(history, 'accuracy')\nplot_graphs(history, 'loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\n\n# Assuming you have test data (test_ids and test_labels) and the trained model (model)\n\n# Predict labels for test data\npredictions = model.predict(test_ids)\npredicted_labels = (predictions > 0.5).astype(int)  # Convert probabilities to binary labels\n\n# Generate classification report\nprint(\"Classification Report:\")\nprint(classification_report(test_labels, predicted_labels))\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(test_labels, predicted_labels)\nprecision = precision_score(test_labels, predicted_labels)\nrecall = recall_score(test_labels, predicted_labels)\nf1 = f1_score(test_labels, predicted_labels)\n\nprint(accuracy)\nprint(precision)\nprint(recall)\nprint(f1)\n\n# Predict labels for test data\npredictions = model.predict(test_ids)\npredicted_labels = (predictions > 0.5).astype(int)  # Convert probabilities to binary labels\n\n# Generate confusion matrix\ncm = confusion_matrix(test_labels, predicted_labels)\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Robert**","metadata":{}},{"cell_type":"code","source":"\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom transformers import TFRobertaModel, RobertaTokenizer\nfrom sklearn.model_selection import train_test_split\n\nPRE_TRAINED_MODEL_NAME = 'roberta-base'\ntokenizer = RobertaTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n\n\nroberta_encoder = TFRobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\ninput_word_ids = tf.keras.Input(shape=(16,), dtype=tf.int32, name=\"input_word_ids\")\nembedding = roberta_encoder([input_word_ids])[0]  # Accessing the output of RoBERTa model\ndense = tf.keras.layers.Lambda(lambda seq: seq[:, 0, :])(embedding)\ndense = tf.keras.layers.Dense(128, activation='relu')(dense)\ndense = tf.keras.layers.Dropout(0.5)(dense)\noutput = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n\nmodel = tf.keras.Model(inputs=[input_word_ids], outputs=output)\n\nmodel.compile(tf.keras.optimizers.Adam(1e-6), loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nhistory = model.fit(x=train_ids, y=train_labels, epochs=100, batch_size=32, validation_data=(test_ids, test_labels), callbacks=[early_stopping])\n\ndef plot_graphs(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_'+string])\n    plt.show()\n\nplot_graphs(history, 'accuracy')\nplot_graphs(history, 'loss')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\n\n# Assuming you have test data (test_ids and test_labels) and the trained model (model)\n\n# Predict labels for test data\npredictions = model.predict(test_ids)\npredicted_labels = (predictions > 0.5).astype(int)  # Convert probabilities to binary labels\n\n# Generate classification report\nprint(\"Classification Report:\")\nprint(classification_report(test_labels, predicted_labels))\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(test_labels, predicted_labels)\nprecision = precision_score(test_labels, predicted_labels)\nrecall = recall_score(test_labels, predicted_labels)\nf1 = f1_score(test_labels, predicted_labels)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1-score:\", f1)\n\n# Predict labels for test data\npredictions = model.predict(test_ids)\npredicted_labels = (predictions > 0.5).astype(int)  # Convert probabilities to binary labels\n\n# Generate confusion matrix\ncm = confusion_matrix(test_labels, predicted_labels)\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Mobile Bert**","metadata":{}},{"cell_type":"code","source":"#mobile bert\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom transformers import MobileBertTokenizerFast, TFAutoModelForSequenceClassification\nfrom sklearn.model_selection import train_test_split\n\nPRE_TRAINED_MODEL_NAME = 'google/mobilebert-uncased'\n\n# Load MobileBERT tokenizer\ntokenizer = MobileBertTokenizerFast.from_pretrained(PRE_TRAINED_MODEL_NAME)\n\n# Load MobileBERT model\nmobilebert_encoder = TFAutoModelForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME)\n\n# Define model architecture\ninput_word_ids = tf.keras.Input(shape=(16,), dtype=tf.int32, name=\"input_word_ids\")\noutput = mobilebert_encoder(input_word_ids)[0]  # Accessing the output of the MobileBERT model\noutput = tf.keras.layers.Dense(1, activation='sigmoid')(output)\n\nmodel = tf.keras.Model(inputs=input_word_ids, outputs=output)\n\n# Compile the model\nmodel.compile(tf.keras.optimizers.Adam(1e-6), loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()\n\n# Define early stopping callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n# Train the mode\nhistory = model.fit(x=train_ids, y=train_labels, epochs=150, batch_size=32, validation_data=(test_ids, test_labels), callbacks=[early_stopping])\n\n# Plotting function\ndef plot_graphs(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_'+string])\n    plt.show()\n\n# Plot accuracy and loss graphs\nplot_graphs(history, 'accuracy')\nplot_graphs(history, 'loss')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\n\n# Assuming you have test data (test_ids and test_labels) and the trained model (model)\n\n# Predict labels for test data\npredictions = model.predict(test_ids)\npredicted_labels = (predictions > 0.5).astype(int)  # Convert probabilities to binary labels\n\n# Generate classification report\nprint(\"Classification Report:\")\nprint(classification_report(test_labels, predicted_labels))\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(test_labels, predicted_labels)\nprecision = precision_score(test_labels, predicted_labels)\nrecall = recall_score(test_labels, predicted_labels)\nf1 = f1_score(test_labels, predicted_labels)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1-score:\", f1)\n\n# Predict labels for test data\npredictions = model.predict(test_ids)\npredicted_labels = (predictions > 0.5).astype(int)  # Convert probabilities to binary labels\n\n# Generate confusion matrix\ncm = confusion_matrix(test_labels, predicted_labels)\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Dis-Bert**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom transformers import DistilBertTokenizer, TFDistilBertModel\nfrom sklearn.model_selection import train_test_split\n\n# Assuming you have your data loaded into train_ids, train_labels, test_ids, and test_labels\n\n# Load DistilBERT tokenizer\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n\n# Define model architecture\ninput_word_ids = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"input_word_ids\")\ndistilbert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased', return_dict=True)\noutput = distilbert_model(input_word_ids)\noutput = output.last_hidden_state[:, 0, :]  # Using [CLS] token representation for classification\noutput = tf.keras.layers.Dense(1, activation='sigmoid')(output)\n\nmodel = tf.keras.Model(inputs=input_word_ids, outputs=output)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()\n\n# Define early stopping callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n\n# Train the model\nhistory = model.fit(\n    train_ids, train_labels,\n    epochs=100,\n    batch_size=32,\n    validation_data=(test_ids, test_labels),\n    callbacks=[early_stopping]\n)\n\n# Plot accuracy and loss graphs\ndef plot_graphs(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_'+string])\n    plt.show()\n\nplot_graphs(history, 'accuracy')\nplot_graphs(history, 'loss')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\n\n# Assuming you have test data (test_ids and test_labels) and the trained model (model)\n\n# Predict labels for test data\npredictions = model.predict(test_ids)\npredicted_labels = (predictions > 0.5).astype(int)  # Convert probabilities to binary labels\n\n# Generate classification report\nprint(\"Classification Report:\")\nprint(classification_report(test_labels, predicted_labels))\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(test_labels, predicted_labels)\nprecision = precision_score(test_labels, predicted_labels)\nrecall = recall_score(test_labels, predicted_labels)\nf1 = f1_score(test_labels, predicted_labels)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1-score:\", f1)\n\n# Predict labels for test data\npredictions = model.predict(test_ids)\npredicted_labels = (predictions > 0.5).astype(int)  # Convert probabilities to binary labels\n\n# Generate confusion matrix\ncm = confusion_matrix(test_labels, predicted_labels)\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**GPT-2**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom transformers import GPT2Tokenizer, TFGPT2ForSequenceClassification\nfrom sklearn.model_selection import train_test_split\n\nPRE_TRAINED_MODEL_NAME = 'gpt2'  # Change this to the desired GPT model, like 'gpt2-medium', 'gpt2-large', 'gpt3', etc.\n\n# Load GPT tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n\n# Load GPT model\ngpt_model = TFGPT2ForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME)\n\n# Define model architecture\ninput_word_ids = tf.keras.Input(shape=(128,), dtype=tf.int32, name=\"input_word_ids\")\noutput = gpt_model(input_word_ids)[0]  # Accessing the output of the GPT model\noutput = tf.keras.layers.Dense(1, activation='sigmoid', \n                                kernel_initializer=tf.keras.initializers.GlorotNormal(seed=42))(output)\n\nmodel = tf.keras.Model(inputs=input_word_ids, outputs=output)\n\n# Compile the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\nloss = tf.keras.losses.BinaryCrossentropy(from_logits=False)  # Set from_logits=False\nmetrics = tf.metrics.BinaryAccuracy()\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)\nmodel.summary()\n\n# Define early stopping callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n# Train the model (Assuming you have your data in train_ids, train_labels, test_ids, and test_labels)\nhistory = model.fit(x=train_ids, y=train_labels, epochs=40, batch_size=32, validation_data=(test_ids, test_labels), callbacks=[early_stopping])\n\n# Plotting function\ndef plot_graphs(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_'+string])\n    plt.show()\n\n# Plot accuracy and loss graphs\nplot_graphs(history, 'binary_accuracy')\nplot_graphs(history, 'loss')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\n# Assuming you have test data (test_ids and test_labels) and the trained model (model)\n\n# Predict labels for test data\npredictions = model.predict(test_ids)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# # Assuming 'predictions' contains the probability values with shape (1408, 16, 1)\n# predictions = np.random.rand(1408, 16, 1)  # Example random predictions\n\n# Calculate the mean probability across all tokens\nmean_predictions = np.mean(predictions, axis=1)\n\n# Reshape to (1408, 1)\nmean_predictions = mean_predictions.reshape(-1, 1)\n\n# Print the shape of mean_predictions\nprint(mean_predictions)  # Should print (1408, 1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_labels = (mean_predictions > 0.5).astype(int)  # Convert probabilities to binary labels\n\n# Flatten the labels if needed\ntest_labels_flat = np.ravel(test_labels)\npredicted_labels_flat = np.ravel(predicted_labels)\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(test_labels_flat, predicted_labels_flat)\nprecision = precision_score(test_labels_flat, predicted_labels_flat)\nrecall = recall_score(test_labels_flat, predicted_labels_flat)\nf1 = f1_score(test_labels_flat, predicted_labels_flat)\n\n# Generate confusion matrix\nconf_matrix = confusion_matrix(test_labels_flat, predicted_labels_flat)\n\n# Print evaluation metrics\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1-score:\", f1)\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}